{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function that takes a list of hyperlinks and returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama\n",
      "https://liftblog.com/alabama/\n",
      "Alaska\n",
      "https://liftblog.com/alaska/\n",
      "Arizona\n",
      "https://liftblog.com/arizona/\n",
      "California\n",
      "https://liftblog.com/california/\n",
      "Colorado\n",
      "https://liftblog.com/colorado/\n",
      "Connecticut\n",
      "https://liftblog.com/connecticut/\n",
      "Florida\n",
      "https://liftblog.com/florida/\n",
      "Georgia\n",
      "https://liftblog.com/georgia/\n",
      "Idaho\n",
      "https://liftblog.com/idaho/\n",
      "Illinois\n",
      "https://liftblog.com/illinois/\n",
      "Indiana\n",
      "https://liftblog.com/indiana/\n",
      "Iowa\n",
      "https://liftblog.com/iowa/\n",
      "Kansas\n",
      "https://liftblog.com/kansas/\n",
      "Kentucky\n",
      "https://liftblog.com/kentucky/\n",
      "Maine\n",
      "https://liftblog.com/maine/\n",
      "Maryland\n",
      "https://liftblog.com/wisp-md/\n",
      "Massachusetts\n",
      "https://liftblog.com/massachusetts/\n",
      "Michigan\n",
      "https://liftblog.com/michigan/\n",
      "Minnesota\n",
      "https://liftblog.com/minnesota/\n",
      "Mississippi\n",
      "https://liftblog.com/mississippi/\n",
      "Missouri\n",
      "https://liftblog.com/missouri/\n",
      "Montana\n",
      "https://liftblog.com/montana/\n",
      "Nebraska\n",
      "https://liftblog.com/nebraska/\n",
      "Nevada\n",
      "https://liftblog.com/nevada/\n",
      "New Hampshire\n",
      "https://liftblog.com/new-hampshire\n",
      "New Jersey\n",
      "https://liftblog.com/new-jersey/\n",
      "New Mexico\n",
      "https://liftblog.com/new-mexico/\n",
      "New York\n",
      "https://liftblog.com/new-york/\n",
      "North Carolina\n",
      "https://liftblog.com/north-carolina/\n",
      "North Dakota\n",
      "https://liftblog.com/north-dakota/\n",
      "Ohio\n",
      "https://liftblog.com/ohio/\n",
      "Oregon\n",
      "https://liftblog.com/oregon/\n",
      "Pennsylvania\n",
      "https://liftblog.com/pennsylvania/\n",
      "Rhode Island\n",
      "https://liftblog.com/rhode-island/\n",
      "South Carolina\n",
      "https://liftblog.com/south-carolina/\n",
      "South Dakota\n",
      "https://liftblog.com/south-dakota/\n",
      "Tennessee\n",
      "https://liftblog.com/tennessee/\n",
      "Texas\n",
      "https://liftblog.com/texas/\n",
      "Utah\n",
      "https://liftblog.com/utah/\n",
      "US Virgin Islands\n",
      "https://liftblog.com/us-virgin-islands/\n",
      "Vermont\n",
      "https://liftblog.com/vermont/\n",
      "Virginia\n",
      "https://liftblog.com/virginia/\n",
      "Washington\n",
      "https://liftblog.com/washington/\n",
      "West Virginia\n",
      "https://liftblog.com/west-virginia/\n",
      "Wisconsin\n",
      "https://liftblog.com/wisconsin/\n",
      "Wyoming\n",
      "https://liftblog.com/wyoming/\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://liftblog.com/united-states/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "#create a beautifulsoup object with the page content and choose the appropriate parser\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# grabs container for job postings\n",
    "results = soup.find(id=\"post-1491\")\n",
    "\n",
    "#there are two lists on this page.  first is the states and second is sharing links\n",
    "states = results.find_all(\"ul\")[0].find_all(\"a\")\n",
    "\n",
    "\n",
    "for state in states:\n",
    "    state_name = state.text.strip()\n",
    "    state_link = state['href']\n",
    "    print(state_name)\n",
    "    print(state_link)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montgomery Zoo\n",
      "https://liftblog.com/montgomery-zoo-al/\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://liftblog.com/alabama/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "#create a beautifulsoup object with the page content and choose the appropriate parser\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# grabs container for list of resorts\n",
    "results = soup.find(\"div\", class_=\"entry-content\")\n",
    "\n",
    "ski_resorts = results.find_all(\"li\")[0]\n",
    "\n",
    "for resort in ski_resorts:\n",
    "    resort_name = resort.text.strip()\n",
    "    resort_link = resort['href']\n",
    "    print(resort_name)\n",
    "    print(resort_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://liftblog.com/montgomery-zoo-al/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "#create a beautifulsoup object with the page content and choose the appropriate parser\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "results = soup.find(\"div\", class_=\"entry-content\")\n",
    "\n",
    "#get the link to the google sheet\n",
    "google_sheet = results.find(\"a\")['href']\n",
    "\n",
    "google_page = requests.get(URL)\n",
    "google_soup = BeautifulSoup(google_page.content, \"html.parser\")\n",
    "\n",
    "google_table = google_soup.find_all(\"table\")\n",
    "\n",
    "print(google_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name  Attribute 1  Attribute 2  Attribute 3 label\n",
      "0  ABC           97         7.98            2     A\n",
      "1  DEF           34         5.36            3     B\n",
      "2  GHI           65         4.31            4     B\n",
      "3  JKL           57         3.47            7     A\n",
      "4  MNO           32         9.24            5     A\n"
     ]
    }
   ],
   "source": [
    "sheet_id = \"1XqOtPkiE_Q0dfGSoyxrH730RkwrTczcRbDeJJpqRByQ\"\n",
    "sheet_name = \"sample_1\"\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
